%TCIDATA{OutputFilter=latex2.dll}
%TCIDATA{Version=5.50.0.2890}
%TCIDATA{LaTeXparent=1,1,PabloPadial_TFG_SW.tex}
%TCIDATA{ChildDefaults=%
%chapter:1,page:1
%}


\chapter{Estado de la Cuesti\'{o}n}

\label{cap:estadoDeLaCuestion}

\bigskip

\subsubsection{\textquestiondown Qu\'{e} es un LLM?}

Un LLM (Large Language Models) es un modelo de inteligencia artificial que se
centra en el procesamiento y generaci\'{o}n del lenguaje humano.

Estos modelos de lenguaje se basan en redes neuronales con millones de
par\'{a}metros, entrenados con grandes conjuntos de datos para poder realizar
tareas relacionadas con el lenguaje natural, as\'{\i} como, generaci\'{o}n de
textos, resumenes o traducci\'{o}n.

https://www.pwc.es/es/newlaw-pulse/legaltech/introduccion-modelos-lenguaje-gran-tamano.html

https://es.wikipedia.org/wiki/Modelo\_extenso\_de\_lenguaje

\subsubsection{Historia y evolucion de los LLM}

Se podr\'{\i}a decir que el inicio de los LLM se remonta a 1913 cuando Andrey
Markov analiz\'{o} los patrones de aparici\'{o}n de volcales y consonantes de
la obra en verso

"Eugene Onegin" pudiendo as\'{\i} calcular la probabilidad de que una letra
arbitraria fuese una vocal. Esta investigaci\'{o}n dio lugar a las cadenas de
Markov, donde la probabilidad de que ocurra un evento depende solamente del
evento inmediatamente anterior.

https://blogs.mat.ucm.es/agomez-corral/2021/08/12/de-como-la-poesia-dio-lugar-a-las-cadenas-de-markov-iii/

https://es.wikipedia.org/wiki/Cadena\_de\_M\%C3\%A1rkov

\bigskip

M\'{a}s adelante en 1950 el matem\'{a}tico britanico Alan Turing propuso en su
ensayo Computing Machinery and Intelligence lo que ahora conocemos por Test de Turing.

Este es un test dise\~{n}ado para evaluar las capacidades de una maquina
desarrollar un comportamiento inteligente similar al humano. El Test de Turing
sent\'{o} las bases

para el desarrollo de la inteligencia artificial en un futuro.

https://www.pwc.es/es/newlaw-pulse/legaltech/introduccion-modelos-lenguaje-gran-tamano.html

\bigskip

En el a\~{n}o 1966 el alem\'{a}n Joseph Weizenbaum creo el primer chatbot de
la historia bajo el nombre de ELIZA que utilizaba el procesamiento de lenguaje
natural para

transmitir cierta empat\'{\i}a. Se basaba en patrones de sustituci\'{o}n para
generar respuestas aunque su capacidad de procesamiento y repertorio era muy
escasos. Aun as\'{\i}

el hecho de poder mantener conversaciones humanas fue realemente innovador
para la \'{e}poca.

https://es.wikipedia.org/wiki/Joseph\_Weizenbaum

\bigskip

A lo largo de las pr\'{o}ximas d\'{e}cadas fueron evolucionando los LLM pero
no fue hasta el a\~{n}o 2010 cuando ver\'{\i}an un omportante avance gracias a
la gran evoluci\'{o}n de las redes neuronales y el uso de la GPU para una
mayor eficiencia.

https://es.wikipedia.org/wiki/Red\_neuronal\_artificial\ss 

\bigskip

Sin embargo, habr\'{\i}a que esperar hasta el a\~{n}o 2017 para ver la gran
explosi\'{o}n de los LLM y la inteligencia artificial con la llegada de
modelos de lenguaje como GPT. Es un modelo de lenguaje basado en Transformer
permitiendo as\'{\i} generar texto coherente y de alta calidad. Desde ese
momento hasta la actualidad han seguido perfeccionandose para poder generar
textos de mayor calidad y en distitnos formatos pudiendo procesar como entrada
tambi\'{e}n im\'{a}genes y videos.

